{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Association Analysis of Filipino Cuisine Ingredients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and preview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read JSON files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "def load_recipes(path=\"data/recipes\"):\n",
    "    \"\"\"Combines all recipe data into a single list.\"\"\"\n",
    "    files = [file for file in os.listdir(path)]\n",
    "\n",
    "    recipes = []\n",
    "    for file in files:\n",
    "        file_path = os.path.join(path, file)\n",
    "        with open(file_path, encoding=\"utf-8\") as f:\n",
    "            recipe_data = json.load(f)\n",
    "            recipes.extend(recipe_data)\n",
    "\n",
    "    return recipes\n",
    "\n",
    "\n",
    "recipes = load_recipes()\n",
    "recipes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert JSON to DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "recipe_df = pd.DataFrame(recipes)\n",
    "recipe_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display some statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def plot_ingredient_count_distribution(ingredient_series, figsize=(8, 3)):\n",
    "    \"\"\"Plots the distribution of the number of ingredients in recipes.\"\"\"\n",
    "    counts = ingredient_series.dropna().apply(len)\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.histplot(counts, kde=True, binwidth=1)\n",
    "    plt.title(f\"Number of ingredients in {len(counts)} recipes\")\n",
    "    plt.xlabel(\"Number of ingredients\")\n",
    "    plt.ylabel(\"Number of recipes\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_common_ingredients(\n",
    "    ingredient_series, n=30, most_common=True, figsize=(8, 7)\n",
    "):\n",
    "    \"\"\"Plots the most or least common ingredients.\"\"\"\n",
    "    all_ingredients = ingredient_series.dropna().explode()\n",
    "    ingredient_counts = all_ingredients.value_counts()\n",
    "\n",
    "    if most_common:\n",
    "        top_n_ingredients = ingredient_counts.head(n)\n",
    "    else:\n",
    "        top_n_ingredients = ingredient_counts.tail(n)\n",
    "\n",
    "    ylabels = [\n",
    "        f\"{i[:20]:>20}{'...' if len(i) > 20 else ''}\"\n",
    "        for i in top_n_ingredients.index\n",
    "    ]\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.barplot(x=top_n_ingredients.values, y=ylabels)\n",
    "    indicator = \"Most\" if most_common else \"Least\"\n",
    "    plt.title(f\"Top {n} {indicator} Common Ingredients\")\n",
    "    plt.xlabel(\"Number of Recipes\")\n",
    "    plt.ylabel(\"Ingredient\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_ingredient_count_distribution(recipe_df.ingredients)\n",
    "plot_common_ingredients(recipe_df.ingredients, n=30, most_common=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Remove recipes with no ingredients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_empty_ingredients(recipe_df, column=\"ingredients\"):\n",
    "    \"\"\"Drops rows with empty ingredients.\"\"\"\n",
    "    new_df = recipe_df.dropna(subset=[column])\n",
    "    print(f\"Dropped {recipe_df.shape[0] - new_df.shape[0]} rows.\")\n",
    "    return new_df\n",
    "\n",
    "\n",
    "recipe_df = drop_empty_ingredients(recipe_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ingredients(ingredient_series, path):\n",
    "    \"\"\"Saves the ingredients to a TXT file.\"\"\"\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "\n",
    "    all_ingredients = ingredient_series.dropna().explode()\n",
    "    data = sorted(all_ingredients.unique().astype(str))\n",
    "\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as file:\n",
    "        for ingredient in data:\n",
    "            file.write(f\"{ingredient.strip()}\\n\")\n",
    "\n",
    "\n",
    "save_ingredients(\n",
    "    recipe_df.ingredients,\n",
    "    path=\"data/preprocess_output/0_raw.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Clean ingredient format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "def remove_parentheses(ingredient):\n",
    "    \"\"\"Removes parentheses and content from ingredient strings.\"\"\"\n",
    "    return re.sub(r\" ?\\([^)]+\\)\", \"\", ingredient)\n",
    "\n",
    "\n",
    "def select_first_option(ingredient):\n",
    "    \"\"\"Selects the first option in a string with multiple options.\"\"\"\n",
    "    return ingredient.split(\" or \")[0]\n",
    "\n",
    "\n",
    "def clean_ingredient(ingredient):\n",
    "    \"\"\"Cleans an ingredient string.\"\"\"\n",
    "    ingredient = remove_parentheses(ingredient)\n",
    "    ingredient = select_first_option(ingredient)\n",
    "    return ingredient.lower().strip()\n",
    "\n",
    "\n",
    "recipe_df[\"cleaned\"] = recipe_df.ingredients.progress_apply(\n",
    "    lambda x: [cleaned for i in x if (cleaned := clean_ingredient(i))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_ingredients(\n",
    "    recipe_df.cleaned,\n",
    "    path=\"data/preprocess_output/1_cleaned.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Lemmatize words and remove non-ingredient words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "\n",
    "def correct_noun_pos_tags(token):\n",
    "    \"\"\"Corrects the POS tags of specific tokens.\"\"\"\n",
    "    outliers = [\"cauliflower\", \"baking\"]\n",
    "    if token.text in outliers:\n",
    "        token.pos_ = \"NOUN\"\n",
    "    return token\n",
    "\n",
    "\n",
    "def lemmatize_nouns(ingredient):\n",
    "    \"\"\"Lemmatizes nouns in an ingredient string.\"\"\"\n",
    "    doc = nlp(ingredient)\n",
    "    lemmas = []\n",
    "    for token in doc:\n",
    "        token = correct_noun_pos_tags(token)\n",
    "        if (\n",
    "            token.is_alpha\n",
    "            and not token.is_stop\n",
    "            and token.pos_ in [\"NOUN\", \"PROPN\"]\n",
    "        ):\n",
    "            lemmas.append(token.lemma_)\n",
    "    return \" \".join(lemmas)\n",
    "\n",
    "\n",
    "recipe_df[\"lemmatized\"] = recipe_df.cleaned.progress_apply(\n",
    "    lambda x: [lemmatized for i in x if (lemmatized := lemmatize_nouns(i))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_ingredients(\n",
    "    recipe_df.lemmatized,\n",
    "    path=\"data/preprocess_output/2_lemmatized.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Remove stop words related to culinary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"data/preprocess_input/stopwords.txt\"\n",
    "with open(input_file, encoding=\"utf-8\") as file:\n",
    "    stopwords = file.read().splitlines()\n",
    "\n",
    "\n",
    "def filter_stopwords(text):\n",
    "    \"\"\"Filter out stopwords from a string.\"\"\"\n",
    "    words = []\n",
    "    for word in text.split():\n",
    "        if word not in stopwords:\n",
    "            words.append(word)\n",
    "    return \" \".join(words)\n",
    "\n",
    "\n",
    "recipe_df[\"filtered\"] = recipe_df.lemmatized.progress_apply(\n",
    "    lambda x: [filtered for i in x if (filtered := filter_stopwords(i))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_ingredients(\n",
    "    recipe_df.filtered,\n",
    "    path=\"data/preprocess_output/3_filtered.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Standardize ingredient names at word level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"data/preprocess_input/thesaurus.json\"\n",
    "with open(input_file, encoding=\"utf-8\") as file:\n",
    "    thesaurus = json.load(file)\n",
    "\n",
    "\n",
    "def standardize_at_phrase_level(ingredient):\n",
    "    \"\"\"Replace words in an ingredient with standard names.\"\"\"\n",
    "    words = []\n",
    "    for word in ingredient.split():\n",
    "        words.append(thesaurus.get(word, word))\n",
    "    return \" \".join(words)\n",
    "\n",
    "\n",
    "recipe_df[\"standardized_word\"] = recipe_df.filtered.progress_apply(\n",
    "    lambda x: [\n",
    "        common_name\n",
    "        for i in x\n",
    "        if (common_name := standardize_at_phrase_level(i))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_ingredients(\n",
    "    recipe_df.standardized_word,\n",
    "    path=\"data/preprocess_output/4_standardized_word.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6. Remove duplicate terms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(text):\n",
    "    \"\"\"Remove duplicate terms while preserving order.\"\"\"\n",
    "    seen = set()\n",
    "    unique = []\n",
    "    for word in text.split():\n",
    "        if word not in seen:\n",
    "            unique.append(word)\n",
    "            seen.add(word)\n",
    "    return \" \".join(unique)\n",
    "\n",
    "\n",
    "recipe_df[\"unique\"] = recipe_df.standardized_word.progress_apply(\n",
    "    lambda x: [unique for i in x if (unique := remove_duplicates(i))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_ingredients(\n",
    "    recipe_df.unique,\n",
    "    path=\"data/preprocess_output/5_unique.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7. Standardize ingredient names at phrase level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_at_phrase_level(ingredient):\n",
    "    \"\"\"Replace the whole ingredient string with a standard name.\"\"\"\n",
    "    return thesaurus.get(ingredient, ingredient)\n",
    "\n",
    "\n",
    "recipe_df[\"standardized_phrase\"] = recipe_df.unique.progress_apply(\n",
    "    lambda x: [\n",
    "        standardized\n",
    "        for i in x\n",
    "        if (standardized := standardize_at_phrase_level(i))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_ingredients(\n",
    "    recipe_df.standardized_phrase,\n",
    "    path=\"data/preprocess_output/6_standardized_phrase.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8. Break down ingredients into basic components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"data/preprocess_input/components.json\"\n",
    "with open(input_file, encoding=\"utf8\") as file:\n",
    "    ingredient_components = json.load(file)\n",
    "\n",
    "\n",
    "def break_down_ingredient(ingredient):\n",
    "    \"\"\"Breaks down an ingredient into its components.\"\"\"\n",
    "    components = ingredient_components.get(ingredient, ingredient)\n",
    "    if isinstance(components, str):\n",
    "        return [components]\n",
    "    return components\n",
    "\n",
    "\n",
    "recipe_df[\"components\"] = recipe_df.standardized_phrase.progress_apply(\n",
    "    lambda x: [component for i in x for component in break_down_ingredient(i)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_ingredients(\n",
    "    recipe_df.components,\n",
    "    path=\"data/preprocess_output/7_components.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ingredient_count_distribution(recipe_df.components)\n",
    "plot_common_ingredients(recipe_df.components)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
